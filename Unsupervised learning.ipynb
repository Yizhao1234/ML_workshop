{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means\n",
    "K-means algorithm is used to find a pre-determined number of clusters within unlabeled multidimensional dataset. To implement this algorithm, let's import the required packages and generate two-dimensional dataset containing four distinct blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y_true = make_blobs(n_samples=300, centers=4,\n",
    "                       cluster_std=0.90, random_state=0)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to pick four clusters by eye and K-means does this automatically. However, we use 10 random initializations to see which clusters have minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4,n_init=10)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "As an exercise, you can try making three clusters with 50 random initializations and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = #Enter your code here#\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means is limited to linear cluster boundaries\n",
    "K-means can perform poorly if the clusters have complex shapes like the two_moons data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(200, noise=.05, random_state=0)\n",
    "labels = KMeans(2, random_state=0).fit_predict(X)\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
    "            s=50, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to solve this is to use kenrelized k-means that can be implemented by `SpectralClustering` estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "model = SpectralClustering(n_clusters=2, affinity='nearest_neighbors',\n",
    "                           assign_labels='kmeans')\n",
    "labels = model.fit_predict(X)\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
    "            s=50, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "One of the most common applications of PCA is visualizing high-dimensional datasets. The Breast Cancer data set is a real-valued multivariate data that consists of two classes, where each class signifies whether a patient has breast cancer or not. The two categories are: malignant and benign. The malignant class has 212 samples, whereas the benign class has 357 samples. It has 30 features shared across all classes as you can see by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer()\n",
    "breast_data = breast.data\n",
    "breast_labels = breast.target\n",
    "labels = np.reshape(breast_labels,(569,1))\n",
    "final_breast_data = np.concatenate([breast_data,labels],axis=1)\n",
    "breast_dataset = pd.DataFrame(final_breast_data)\n",
    "features = breast.feature_names\n",
    "features_labels = np.append(features,'label')\n",
    "breast_dataset.columns = features_labels\n",
    "breast_dataset['label'].replace(0, 'Benign',inplace=True)\n",
    "breast_dataset['label'].replace(1, 'Malignant',inplace=True)\n",
    "breast_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run PCA to project high dimensional data into low dimensional principal components. In this regard, we normalize the data and fit the PCA to find the principal components. By running the following code, you will see how the shape of original dataset is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = breast_dataset.loc[:, features].values\n",
    "x_scaled = StandardScaler().fit_transform(x) # normalizing the features\n",
    "from sklearn.decomposition import PCA\n",
    "pca_breast = PCA(n_components=2)\n",
    "principalComponents_breast = pca_breast.fit_transform(x_scaled)\n",
    "principal_breast_Df = pd.DataFrame(data = principalComponents_breast\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "print(\"Original shape: {}\".format(str(x_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(principalComponents_breast.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reducing the dimensionality, we should expect loosing some information. Let's see how much of the information is retained and how much is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Explained variation per principal component: {}'.format(pca_breast.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the `principal component 1` holds 44.2% of the information and `principal component 2` holds only 19% of the information. Note that by this dimensionality reduction 36.8% of the information is lost. Let's plot the 569 samples along the two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1',fontsize=20)\n",
    "plt.ylabel('Principal Component - 2',fontsize=20)\n",
    "plt.title(\"Principal Component Analysis of Breast Cancer Dataset\",fontsize=20)\n",
    "targets = ['Benign', 'Malignant']\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = breast_dataset['label'] == target\n",
    "    plt.scatter(principal_breast_Df.loc[indicesToKeep, 'principal component 1']\n",
    "               , principal_breast_Df.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
