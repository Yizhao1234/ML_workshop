{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Classification\n",
    "In this section, we will go over the KNN algorithm in classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the appropriate packages\n",
    "This time we load the related packages for KNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import urllib.request\n",
    "\n",
    "print('Beginning file download with url...')\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mohammadrashedi/ML_workshop/master/data_knn.csv'\n",
    "urllib.request.urlretrieve(url, 'data_knn.csv')\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mohammadrashedi/ML_workshop/master/iris.png'\n",
    "urllib.request.urlretrieve(url, 'iris.png')\n",
    "print('File download done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s assume that a hobby botanist is interested in distinguishing the species of some iris flowers that she has found. She has collected some measurements associated with each iris: the length and width of the petals and the length and width of the sepals, all measured in centimeters.\n",
    "\n",
    "She also has the measurements of some irises that have been previously identified by an expert botanist as belonging to the species setosa, versicolor, or virginica. For these measurements, she can be certain of which species each iris belongs to. Let’s assume that these are the only species our hobby botanist will encounter in the wild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "image = mpimg.imread(\"iris.png\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a machine learning model that can learn from the measurements of these irises whose species is known, so that we can predict the species for a new iris. Now, let's load and have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_knn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have two features for the data, it can be plotted by using a single scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x=\"Sepal Length\", y=\"Sepal Width\", color=\"Species\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the data as numpy arrays from the data frame `df`. Here we encode the output labels to be integers for visualization purposes using `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Species', axis=1).to_numpy()\n",
    "y_text = df['Species'].to_numpy()\n",
    "y = LabelEncoder().fit_transform(y_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "Let's use 60% (90 examples) of the data for training, 20% for validation (30 examples) and the remaining 20% (30 examples) as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_vt, y_train, y_vt) = train_test_split(X, y, test_size=0.4)\n",
    "(X_validation, X_test, y_validation, y_test) = train_test_split(X_vt, y_vt, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the KNN model\n",
    "Here we create an object of the class `KNeighborsClassifier` and name the resulting object as `knn`. Remember that a value should be specified for $k$ which is called `n_neighbors` in scikit-learn implementation.\n",
    "\n",
    "All of the measurements in our dataset are of length and are in centimeters, and as a result the distance measure would be Euclidian.  For `KNeighborsClassifier`, the default distance measure or `metric` (as the argument is called in scikit-learn) is the $L_p$ measure or the Minkowski distance (`metric=minkowski` in scikit-learn call) with $p=2$ (`p=2` in `KNeighborsClassifier` arguments), which is nothing other than the $L_2$ distance measure or the Eucliadian distance.\n",
    "\n",
    "The other parameter that should be determined is the number of neighbors. Let's start with a value of 1 for `n_neighbors`. The documentation for `KNeighborsClassifier` can be found here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1,p=2,metric='minkowski')\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the our model using plotly heatmaps which shows regions where points will be predicted in different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_steps = 500\n",
    "\n",
    "(x_vis_0_min, x_vis_0_max) = (X[:, 0].min() - 0.5, X[:, 0].max() + 0.5)\n",
    "(x_vis_1_min, x_vis_1_max) = (X[:, 1].min() - 0.5, X[:, 1].max() + 0.5)\n",
    "\n",
    "x_vis_0_range = np.linspace(x_vis_0_min, x_vis_0_max, detail_steps)\n",
    "x_vis_1_range = np.linspace(x_vis_1_min, x_vis_1_max, detail_steps)\n",
    "\n",
    "(XX_vis_0, XX_vis_1) = np.meshgrid(x_vis_0_range, x_vis_1_range)\n",
    "X_vis = np.c_[XX_vis_0.reshape(-1), XX_vis_1.reshape(-1)]\n",
    "\n",
    "yhat_vis = knn.predict(X_vis)\n",
    "YYhat_vis = yhat_vis.reshape(XX_vis_0.shape)\n",
    "\n",
    "region_colorscale = [\n",
    "                     [0.0, 'rgb(199, 204, 249)'],\n",
    "                     [0.5, 'rgb(235, 185, 177)'],\n",
    "                     [1.0, 'rgb(159, 204, 186)']\n",
    "                    ]\n",
    "points_colorscale = [\n",
    "                     [0.0, 'rgb(99, 110, 250)'],\n",
    "                     [0.5, 'rgb(239, 85, 59)'],\n",
    "                     [1.0, 'rgb(66, 204, 150)']\n",
    "                    ]\n",
    "fig2 = go.Figure(\n",
    "                data=[\n",
    "                      go.Heatmap(x=x_vis_0_range,\n",
    "                                 y=x_vis_1_range,\n",
    "                                 z=YYhat_vis,\n",
    "                                 colorscale=region_colorscale,\n",
    "                                 showscale=False),\n",
    "                      go.Scatter(x=df['Sepal Length'], \n",
    "                                 y=df['Sepal Width'],\n",
    "                                 mode='markers',\n",
    "                                 text=df['Species'],\n",
    "                                 name='',\n",
    "#                                 showscale=False,\n",
    "                                 marker=dict(\n",
    "                                             color=y,\n",
    "                                             colorscale=points_colorscale\n",
    "                                            )\n",
    "                                )\n",
    "                     ],\n",
    "                     layout=go.Layout(\n",
    "                                      xaxis=dict(title='Sepal Length'),\n",
    "                                      yaxis=dict(title='Sepal Width')\n",
    "                                     )\n",
    "               )\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and evaluation\n",
    "Now, we evaluate the model with `k=1` using training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Accuracy on validation set: {:.3f}\".format(knn.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high training accuracy was expected and we also expect the accuracy on validation points not be that high. That is becuase we are probably overfitting by using $k=1$. Let's use other values of $k$ or `n_neighbors`. \n",
    "### Exercise\n",
    "Use $k=3$, build your model, fit it to your training data, and assign it to `knn3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3= # Write your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat3_vis = knn3.predict(X_vis)\n",
    "YYhat3_vis = yhat3_vis.reshape(XX_vis_0.shape)\n",
    "\n",
    "fig3 = fig2\n",
    "fig3['data'][0]['z'] = YYhat3_vis\n",
    "\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(knn3.score(X_train, y_train)))\n",
    "print(\"Accuracy on validation set: {:.3f}\".format(knn3.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the model performance with different values of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "# build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors,p=2,metric='minkowski')\n",
    "    clf.fit(X_train, y_train)\n",
    "# record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "# record generalization accuracy\n",
    "    validation_accuracy.append(clf.score(X_validation, y_validation))\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"Training accuracy\")\n",
    "plt.plot(neighbors_settings, validation_accuracy, label=\"Validation accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, you might have got a sense about the performance of different models. \n",
    "### Exercise\n",
    "Let's pick the best one (based on the plot above) and verify it by implementing for your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best= # Enter your code here\n",
    "knn_best.fit(X_train,y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(knn_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Regression\n",
    "There is also a regression variant of the k-nearest neighbors algorithm. Again, let’s generate some data for regression purpose and then plot the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "plt.figure()\n",
    "plt.title('Sample regression problem with one input variable')\n",
    "X_R1, y_R1 = make_regression(n_samples = 100, n_features=1,\n",
    "                            n_informative=1, bias = 150.0,\n",
    "                            noise = 30, random_state=0)\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we call the KNN regressor from the library and again divide the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "(X_train, X_vt, y_train, y_vt) = train_test_split(X_R1, y_R1, test_size=0.4)\n",
    "(X_validation, X_test, y_validation, y_test) = train_test_split(X_vt, y_vt, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we evaluate the regressor by considering 5 neighbor data points. To do so, we print the training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnreg = KNeighborsRegressor(n_neighbors = 5).fit(X_train, y_train)\n",
    "print('R-squared training score: {:.3f}'\n",
    "     .format(knnreg.score(X_train, y_train)))\n",
    "print('R-squared validation score: {:.3f}'\n",
    "     .format(knnreg.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the predicted data points against the true values for KNN regressors with 1, 3, and 5 neighbors in a discrete fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 3, figsize=(15,6))\n",
    "X_predict_input = np.linspace(-3, 3, 50).reshape(-1,1)\n",
    "\n",
    "for thisaxis, K in zip(subaxes, [1, 3, 5]):\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = K).fit(X_train, y_train)\n",
    "    y_predict_output = knnreg.predict(X_predict_input)\n",
    "    thisaxis.set_xlim([-2.5, 0.75])\n",
    "    thisaxis.plot(X_predict_input, y_predict_output, '^', markersize = 10,\n",
    "                 label='Predicted', alpha=0.8)\n",
    "    thisaxis.plot(X_train, y_train, 'o', label='True Value', alpha=0.8)\n",
    "    thisaxis.set_xlabel('Input feature')\n",
    "    thisaxis.set_ylabel('Target value')\n",
    "    thisaxis.set_title('KNN regression (K={})'.format(K))\n",
    "    thisaxis.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we plot the results of the KNN regressor but with a fitted continuous line through the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot k-NN regression on sample dataset for different values of K\n",
    "fig, subaxes = plt.subplots(5, 1, figsize=(5,20))\n",
    "X_predict_input = np.linspace(-3, 3, 500).reshape(-1,1)\n",
    "\n",
    "for thisaxis, K in zip(subaxes,[1, 3, 7, 15, 55]):\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = K).fit(X_train, y_train)\n",
    "    y_predict_output = knnreg.predict(X_predict_input)\n",
    "    train_score = knnreg.score(X_train, y_train)\n",
    "    validation_score = knnreg.score(X_validation, y_validation)\n",
    "    thisaxis.plot(X_predict_input, y_predict_output)\n",
    "    thisaxis.plot(X_train, y_train, 'o', alpha=0.9, label='Train')\n",
    "    thisaxis.plot(X_validation, y_validation, '^', alpha=0.9, label='Test')\n",
    "    thisaxis.set_xlabel('Input feature')\n",
    "    thisaxis.set_ylabel('Target value')\n",
    "    thisaxis.set_title('KNN Regression (K={})\\n\\\n",
    "Train $R^2 = {:.3f}$,  Test $R^2 = {:.3f}$'\n",
    "                      .format(K, train_score, validation_score))\n",
    "    thisaxis.legend()\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, based on the above results, we may guess what range of values for the neighbors are more reasonable. Let's compare the validation and training data in terms of the accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "# try n_neighbors from 1 to 20\n",
    "neighbors_settings = range(1, 20)\n",
    "for n_neighbors in neighbors_settings:\n",
    "# build the model\n",
    "    clf = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "# record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "# record generalization accuracy\n",
    "    validation_accuracy.append(clf.score(X_validation, y_validation))\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"Training accuracy\")\n",
    "plt.plot(neighbors_settings, validation_accuracy, label=\"Validation accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
